"""
ç”Ÿæˆå™¨æ¨¡å—
è´Ÿè´£åŸºäºæ£€ç´¢å†…å®¹ç”Ÿæˆç­”æ¡ˆ
"""

from typing import List, Dict, Any
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_ollama import ChatOllama
# åŠ è½½.envæ–‡ä»¶ - ä»é¡¹ç›®æ ¹ç›®å½•
from dotenv import load_dotenv
import os
from pathlib import Path
# è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
env_path = project_root / ".env"

# åŠ è½½.envæ–‡ä»¶
load_dotenv(env_path)

# ä»ç¯å¢ƒå˜é‡è·å–OllamaåŸºç¡€URLï¼Œé»˜è®¤ä¸ºlocalhost:11434
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")


class Generator:
    """ç”Ÿæˆå™¨ç±»"""
    
    def __init__(self, 
                 model_name: str = "gpt-oss:20b",
                 temperature: float = 0.7,
                 max_tokens: int = 1000):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            model_name: Ollamaæ¨¡å‹åç§°
            temperature: ç”Ÿæˆæ¸©åº¦
            max_tokens: æœ€å¤§tokenæ•°
        """
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        # åˆå§‹åŒ–èŠå¤©æ¨¡å‹
        self.model = self._init_model()
        
        # åˆ›å»ºæç¤ºæ¨¡æ¿
        self.prompt_template = self._create_prompt_template()
        
        # åˆ›å»ºç”Ÿæˆé“¾
        self.chain = self._create_chain()
    
    def _init_model(self) -> ChatOllama:
        """åˆå§‹åŒ–èŠå¤©æ¨¡å‹"""
        try:
            print(f"ğŸ¤– åˆå§‹åŒ–OllamaèŠå¤©æ¨¡å‹: {self.model_name}")
            return ChatOllama(
                model=self.model_name,
                temperature=self.temperature,
                num_predict=self.max_tokens,
                base_url=OLLAMA_BASE_URL
            )
        except Exception as e:
            raise Exception(f"èŠå¤©æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    def _create_prompt_template(self) -> ChatPromptTemplate:
        """åˆ›å»ºæç¤ºæ¨¡æ¿"""
        template = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚å›ç­”:
1. åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯æä¾›å‡†ç¡®ã€ç›¸å…³çš„ç­”æ¡ˆ
2. å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. ä¿æŒå›ç­”ç®€æ´æ˜äº†
4. å¦‚æœé€‚ç”¨ï¼Œå¯ä»¥å¼•ç”¨ä¸Šä¸‹æ–‡ä¸­çš„å…·ä½“ä¿¡æ¯

å›ç­”:
"""
        return ChatPromptTemplate.from_template(template)
    
    def _create_chain(self):
        """åˆ›å»ºç”Ÿæˆé“¾"""
        return self.prompt_template | self.model | StrOutputParser()
    
    def generate_answer(self, 
                       question: str, 
                       context_documents: List[Document]) -> str:
        """
        åŸºäºæ£€ç´¢å†…å®¹ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context_documents: æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£
            
        Returns:
            ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        if not context_documents:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
        
        try:
            # æ„å»ºä¸Šä¸‹æ–‡
            context = self._build_context(context_documents)
            
            # ç”Ÿæˆç­”æ¡ˆ
            answer = self.chain.invoke({
                "context": context,
                "question": question
            })
            
            return answer
            
        except Exception as e:
            raise Exception(f"ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def _build_context(self, documents: List[Document]) -> str:
        """
        æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        context_parts = []
        
        for i, doc in enumerate(documents, 1):
            # æ·»åŠ æ–‡æ¡£å†…å®¹
            content = doc.page_content.strip()
            
            # æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
            metadata_info = []
            if doc.metadata:
                if "source" in doc.metadata:
                    metadata_info.append(f"æ¥æº: {doc.metadata['source']}")
                if "type" in doc.metadata:
                    metadata_info.append(f"ç±»å‹: {doc.metadata['type']}")
            
            metadata_str = f" ({', '.join(metadata_info)})" if metadata_info else ""
            
            context_parts.append(f"[{i}] {content}{metadata_str}")
        
        return "\n\n".join(context_parts)
    
    def generate_answer_with_sources(self, 
                                   question: str, 
                                   context_documents: List[Document]) -> Dict[str, Any]:
        """
        ç”Ÿæˆç­”æ¡ˆå¹¶åŒ…å«æ¥æºä¿¡æ¯
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context_documents: æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£
            
        Returns:
            åŒ…å«ç­”æ¡ˆå’Œæ¥æºä¿¡æ¯çš„å­—å…¸
        """
        answer = self.generate_answer(question, context_documents)
        
        # æ„å»ºæ¥æºä¿¡æ¯
        sources = []
        for doc in context_documents:
            source_info = {
                "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
                "metadata": doc.metadata
            }
            sources.append(source_info)
        
        return {
            "answer": answer,
            "sources": sources,
            "sources_count": len(sources)
        }
    
    def update_model_config(self, 
                          model_name: str = None,
                          temperature: float = None,
                          max_tokens: int = None):
        """
        æ›´æ–°æ¨¡å‹é…ç½®
        
        Args:
            model_name: æ¨¡å‹åç§°
            temperature: ç”Ÿæˆæ¸©åº¦
            max_tokens: æœ€å¤§tokenæ•°
        """
        config_updated = False
        
        if model_name and model_name != self.model_name:
            self.model_name = model_name
            config_updated = True
        
        if temperature is not None and temperature != self.temperature:
            self.temperature = temperature
            config_updated = True
        
        if max_tokens is not None and max_tokens != self.max_tokens:
            self.max_tokens = max_tokens
            config_updated = True
        
        if config_updated:
            # é‡æ–°åˆå§‹åŒ–æ¨¡å‹å’Œé“¾
            self.model = self._init_model()
            self.chain = self._create_chain()
            print(f"ğŸ”„ ç”Ÿæˆå™¨é…ç½®å·²æ›´æ–°: model={self.model_name}, temp={self.temperature}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        
        Returns:
            æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        return {
            "model_name": self.model_name,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "model_type": "ChatOllama"
        }


# æµ‹è¯•å‡½æ•°
def test_generator():
    """æµ‹è¯•ç”Ÿæˆå™¨"""
    print("ğŸ§ª æµ‹è¯•ç”Ÿæˆå™¨...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    from langchain_core.documents import Document
    
    test_documents = [
        Document(
            page_content="æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä¸“æ³¨äºç®—æ³•å’Œç»Ÿè®¡æ¨¡å‹ã€‚",
            metadata={"source": "ml_guide", "type": "definition"}
        ),
        Document(
            page_content="æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œå¤„ç†å¤æ‚ä»»åŠ¡ã€‚",
            metadata={"source": "dl_tutorial", "type": "definition"}
        )
    ]
    
    # æµ‹è¯•1: åŸºæœ¬ç­”æ¡ˆç”Ÿæˆ
    print("\nğŸ¤– æµ‹è¯•åŸºæœ¬ç­”æ¡ˆç”Ÿæˆ...")
    try:
        generator = Generator()
        
        question = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
        answer = generator.generate_answer(question, test_documents)
        
        print(f"   é—®é¢˜: {question}")
        print(f"   ç­”æ¡ˆ: {answer[:100]}...")
        print("   âœ… åŸºæœ¬ç­”æ¡ˆç”Ÿæˆæµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"   âš ï¸ åŸºæœ¬ç­”æ¡ˆç”Ÿæˆæµ‹è¯•å¤±è´¥: {str(e)}")
        print("   å¯èƒ½æ˜¯OllamaæœåŠ¡æœªå¯åŠ¨ï¼Œè·³è¿‡è¯¦ç»†æµ‹è¯•")
        return
    
    # æµ‹è¯•2: å¸¦æ¥æºçš„ç­”æ¡ˆç”Ÿæˆ
    print("\nğŸ“š æµ‹è¯•å¸¦æ¥æºçš„ç­”æ¡ˆç”Ÿæˆ...")
    try:
        generator = Generator()
        
        question = "æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"
        result = generator.generate_answer_with_sources(question, test_documents)
        
        print(f"   é—®é¢˜: {question}")
        print(f"   ç­”æ¡ˆ: {result['answer'][:100]}...")
        print(f"   æ¥æºæ•°é‡: {result['sources_count']}")
        print("   âœ… å¸¦æ¥æºç­”æ¡ˆç”Ÿæˆæµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"   âš ï¸ å¸¦æ¥æºç­”æ¡ˆç”Ÿæˆæµ‹è¯•å¤±è´¥: {str(e)}")
    
    # æµ‹è¯•3: ç©ºä¸Šä¸‹æ–‡å¤„ç†
    print("\nâš ï¸ æµ‹è¯•ç©ºä¸Šä¸‹æ–‡å¤„ç†...")
    try:
        generator = Generator()
        
        question = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
        answer = generator.generate_answer(question, [])
        
        print(f"   é—®é¢˜: {question}")
        print(f"   ç­”æ¡ˆ: {answer}")
        print("   âœ… ç©ºä¸Šä¸‹æ–‡å¤„ç†æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"   âš ï¸ ç©ºä¸Šä¸‹æ–‡å¤„ç†æµ‹è¯•å¤±è´¥: {str(e)}")
    
    # æµ‹è¯•4: æ¨¡å‹é…ç½®
    print("\nâš™ï¸ æµ‹è¯•æ¨¡å‹é…ç½®...")
    try:
        generator = Generator()
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        info = generator.get_model_info()
        print(f"   åˆå§‹é…ç½®: {info}")
        
        # æ›´æ–°é…ç½®
        generator.update_model_config(temperature=0.5, max_tokens=500)
        
        updated_info = generator.get_model_info()
        print(f"   æ›´æ–°åé…ç½®: {updated_info}")
        
        print("   âœ… æ¨¡å‹é…ç½®æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"   âš ï¸ æ¨¡å‹é…ç½®æµ‹è¯•å¤±è´¥: {str(e)}")
    
    # æµ‹è¯•5: ä¸Šä¸‹æ–‡æ„å»º
    print("\nğŸ“ æµ‹è¯•ä¸Šä¸‹æ–‡æ„å»º...")
    try:
        generator = Generator()
        
        context = generator._build_context(test_documents)
        print(f"   æ„å»ºçš„ä¸Šä¸‹æ–‡:\n{context[:200]}...")
        
        print("   âœ… ä¸Šä¸‹æ–‡æ„å»ºæµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"   âš ï¸ ä¸Šä¸‹æ–‡æ„å»ºæµ‹è¯•å¤±è´¥: {str(e)}")
    
    print("\nğŸ¯ ç”Ÿæˆå™¨æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_generator()