"""
æ£€ç´¢å™¨æ¨¡å—
è´Ÿè´£ä»å‘é‡å­˜å‚¨ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£
"""

from typing import List, Optional, Dict, Any
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from langchain_core.vectorstores import VectorStore


class Retriever:
    """æ£€ç´¢å™¨ç±»"""
    
    def __init__(self, vector_store: VectorStore, search_type: str = "similarity"):
        """
        åˆå§‹åŒ–æ£€ç´¢å™¨
        
        Args:
            vector_store: å‘é‡å­˜å‚¨å®ä¾‹
            search_type: æœç´¢ç±»å‹ï¼Œæ”¯æŒ "similarity" æˆ– "mmr"
        """
        self.vector_store = vector_store
        self.search_type = search_type

        # åˆ›å»ºLangChainæ£€ç´¢å™¨
        self.retriever = self._create_retriever()
    
    def _create_retriever(self) -> BaseRetriever:
        """åˆ›å»ºæ£€ç´¢å™¨å®ä¾‹"""
        search_kwargs = {"k": 3}  # é»˜è®¤è¿”å›3ä¸ªæ–‡æ¡£
        
        if self.search_type == "mmr":
            # MMR (Maximal Marginal Relevance) æ£€ç´¢
            return self.vector_store.as_retriever(
                search_type="mmr",
                search_kwargs={"k": 3, "fetch_k": 10}
            )
        else:
            # ç›¸ä¼¼æ€§æ£€ç´¢
            return self.vector_store.as_retriever(
                search_type="similarity",
                search_kwargs=search_kwargs
            )
    
    def search(self, 
               query: str, 
               k: int = 3, 
               filters: Optional[Dict[str, Any]] = None) -> List[Document]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›çš„æ–‡æ¡£æ•°é‡
            filters: å…ƒæ•°æ®è¿‡æ»¤å™¨
            
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # æ›´æ–°æ£€ç´¢å™¨é…ç½®
            if k != 3:
                self.retriever.search_kwargs["k"] = k
            
            if filters:
                self.retriever.search_kwargs["filter"] = filters
            
            # æ‰§è¡Œæ£€ç´¢
            results = self.retriever.invoke(query)
            
            return results
            
        except Exception as e:
            raise Exception(f"æ£€ç´¢å¤±è´¥: {str(e)}")
    
    def search_with_score(self, 
                         query: str, 
                         k: int = 3, 
                         filters: Optional[Dict[str, Any]] = None) -> List[tuple]:
        """
        å¸¦ç›¸ä¼¼åº¦åˆ†æ•°çš„æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›çš„æ–‡æ¡£æ•°é‡
            filters: å…ƒæ•°æ®è¿‡æ»¤å™¨
            
        Returns:
            (æ–‡æ¡£, åˆ†æ•°) å…ƒç»„åˆ—è¡¨
        """
        try:
            # ç›´æ¥ä½¿ç”¨å‘é‡å­˜å‚¨çš„å¸¦åˆ†æ•°æœç´¢
            results = self.vector_store.similarity_search_with_score(
                query=query,
                k=k,
                filter=filters
            )
            
            return results
            
        except Exception as e:
            raise Exception(f"å¸¦åˆ†æ•°æ£€ç´¢å¤±è´¥: {str(e)}")
    
    def search_with_relevance_threshold(self, 
                                      query: str, 
                                      k: int = 3,
                                      score_threshold: float = 0.5,
                                      filters: Optional[Dict[str, Any]] = None) -> List[Document]:
        """
        å¸¦ç›¸å…³æ€§é˜ˆå€¼çš„æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›çš„æ–‡æ¡£æ•°é‡
            score_threshold: åˆ†æ•°é˜ˆå€¼ï¼Œåªè¿”å›åˆ†æ•°é«˜äºæ­¤å€¼çš„æ–‡æ¡£
            filters: å…ƒæ•°æ®è¿‡æ»¤å™¨
            
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # è·å–å¸¦åˆ†æ•°çš„ç»“æœ
            scored_results = self.search_with_score(query, k, filters)
            
            # è¿‡æ»¤ä½äºé˜ˆå€¼çš„æ–‡æ¡£
            filtered_results = [
                doc for doc, score in scored_results 
                if score >= score_threshold
            ]
            
            return filtered_results
            
        except Exception as e:
            raise Exception(f"å¸¦é˜ˆå€¼æ£€ç´¢å¤±è´¥: {str(e)}")
    
    def hybrid_search(self, 
                     query: str, 
                     k: int = 3,
                     keyword_weight: float = 0.3,
                     semantic_weight: float = 0.7) -> List[Document]:
        """
        æ··åˆæ£€ç´¢ï¼ˆå…³é”®è¯ + è¯­ä¹‰ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›çš„æ–‡æ¡£æ•°é‡
            keyword_weight: å…³é”®è¯æ£€ç´¢æƒé‡
            semantic_weight: è¯­ä¹‰æ£€ç´¢æƒé‡
            
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # è¯­ä¹‰æ£€ç´¢
            semantic_results = self.search(query, k)
            
            # ç®€å•çš„å…³é”®è¯æ£€ç´¢ï¼ˆåŸºäºåŒ…å«å…³ç³»ï¼‰
            keyword_results = []
            query_words = set(query.lower().split())
            
            # è·å–æ‰€æœ‰æ–‡æ¡£è¿›è¡Œå…³é”®è¯åŒ¹é…
            # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨æ›´é«˜æ•ˆçš„å…³é”®è¯æ£€ç´¢
            all_docs = self.vector_store.get()
            if all_docs and "documents" in all_docs:
                for i, doc_content in enumerate(all_docs["documents"]):
                    doc_words = set(doc_content.lower().split())
                    common_words = query_words & doc_words
                    if common_words:
                        # åˆ›å»ºä¸´æ—¶æ–‡æ¡£å¯¹è±¡
                        temp_doc = Document(
                            page_content=doc_content,
                            metadata=all_docs["metadatas"][i] if "metadatas" in all_docs else {}
                        )
                        keyword_results.append(temp_doc)
            
            # ç®€å•çš„æ··åˆç­–ç•¥ï¼ˆå–å‰kä¸ªï¼‰
            combined_results = semantic_results[:int(k * semantic_weight)] + \
                             keyword_results[:int(k * keyword_weight)]
            
            # å»é‡
            seen_contents = set()
            unique_results = []
            for doc in combined_results:
                if doc.page_content not in seen_contents:
                    seen_contents.add(doc.page_content)
                    unique_results.append(doc)
            
            return unique_results[:k]
            
        except Exception as e:
            print(f"âš ï¸ æ··åˆæ£€ç´¢å¤±è´¥ï¼Œå›é€€åˆ°è¯­ä¹‰æ£€ç´¢: {str(e)}")
            return self.search(query, k)
    
    def get_retriever_info(self) -> Dict[str, Any]:
        """
        è·å–æ£€ç´¢å™¨ä¿¡æ¯
        
        Returns:
            æ£€ç´¢å™¨ä¿¡æ¯å­—å…¸
        """
        return {
            "search_type": self.search_type,
            "default_k": self.retriever.search_kwargs.get("k", 3),
            "vector_store_type": type(self.vector_store).__name__
        }
    
    def update_search_config(self, 
                           search_type: Optional[str] = None,
                           k: Optional[int] = None,
                           filters: Optional[Dict[str, Any]] = None):
        """
        æ›´æ–°æ£€ç´¢é…ç½®
        
        Args:
            search_type: æœç´¢ç±»å‹
            k: è¿”å›æ–‡æ¡£æ•°é‡
            filters: å…ƒæ•°æ®è¿‡æ»¤å™¨
        """
        if search_type and search_type != self.search_type:
            self.search_type = search_type
            self.retriever = self._create_retriever()
        
        if k:
            self.retriever.search_kwargs["k"] = k
        
        if filters is not None:
            self.retriever.search_kwargs["filter"] = filters


# æµ‹è¯•å‡½æ•°
def test_retriever():
    """æµ‹è¯•æ£€ç´¢å™¨"""
    print("ğŸ§ª æµ‹è¯•æ£€ç´¢å™¨...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    from langchain_core.documents import Document
    from Sandbox.rag_system.core.vector_store import VectorStoreManager
    
    test_documents = [
        Document(
            page_content="æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä¸“æ³¨äºç®—æ³•å’Œç»Ÿè®¡æ¨¡å‹",
            metadata={"source": "ml_intro", "type": "definition", "topic": "ml"}
        ),
        Document(
            page_content="æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œå¤„ç†å¤æ‚æ¨¡å¼è¯†åˆ«ä»»åŠ¡",
            metadata={"source": "dl_intro", "type": "definition", "topic": "dl"}
        ),
        Document(
            page_content="è‡ªç„¶è¯­è¨€å¤„ç†è®©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€",
            metadata={"source": "nlp_intro", "type": "application", "topic": "nlp"}
        ),
        Document(
            page_content="è®¡ç®—æœºè§†è§‰å¤„ç†å›¾åƒå’Œè§†é¢‘æ•°æ®",
            metadata={"source": "cv_intro", "type": "application", "topic": "cv"}
        )
    ]
    
    # æµ‹è¯•1: åŸºæœ¬æ£€ç´¢
    print("\nğŸ” æµ‹è¯•åŸºæœ¬æ£€ç´¢...")
    try:
        import tempfile
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # åˆå§‹åŒ–å‘é‡å­˜å‚¨
            store_manager = VectorStoreManager(persist_directory=temp_dir)
            store_manager.initialize_store(test_documents)
            
            # åˆ›å»ºæ£€ç´¢å™¨
            retriever = Retriever(store_manager.vector_store)
            
            # åŸºæœ¬æœç´¢
            results = retriever.search("æœºå™¨å­¦ä¹ ", k=2)
            print(f"   åŸºæœ¬æ£€ç´¢: æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
            
            # æ£€ç´¢å™¨ä¿¡æ¯
            info = retriever.get_retriever_info()
            print(f"   æ£€ç´¢å™¨é…ç½®: {info}")
            
    except Exception as e:
        print(f"   âš ï¸ åŸºæœ¬æ£€ç´¢æµ‹è¯•å¤±è´¥: {str(e)}")
        print("   å¯èƒ½æ˜¯ä¾èµ–é—®é¢˜ï¼Œè·³è¿‡è¯¦ç»†æµ‹è¯•")
        return
    
    # æµ‹è¯•2: å¸¦åˆ†æ•°æ£€ç´¢
    print("\nğŸ“Š æµ‹è¯•å¸¦åˆ†æ•°æ£€ç´¢...")
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            store_manager = VectorStoreManager(persist_directory=temp_dir)
            store_manager.initialize_store(test_documents)
            
            retriever = Retriever(store_manager.vector_store)
            
            # å¸¦åˆ†æ•°æœç´¢
            scored_results = retriever.search_with_score("æ·±åº¦å­¦ä¹ ", k=2)
            print(f"   å¸¦åˆ†æ•°æ£€ç´¢: æ‰¾åˆ° {len(scored_results)} ä¸ªç›¸å…³æ–‡æ¡£")
            
            if scored_results:
                for i, (doc, score) in enumerate(scored_results):
                    print(f"     æ–‡æ¡£{i+1}: åˆ†æ•°={score:.4f}, å†…å®¹={doc.page_content[:50]}...")
            
    except Exception as e:
        print(f"   âš ï¸ å¸¦åˆ†æ•°æ£€ç´¢æµ‹è¯•å¤±è´¥: {str(e)}")
    
    # æµ‹è¯•3: å…ƒæ•°æ®è¿‡æ»¤
    print("\nğŸ¯ æµ‹è¯•å…ƒæ•°æ®è¿‡æ»¤...")
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            store_manager = VectorStoreManager(persist_directory=temp_dir)
            store_manager.initialize_store(test_documents)
            
            retriever = Retriever(store_manager.vector_store)
            
            # ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤
            filtered_results = retriever.search(
                "äººå·¥æ™ºèƒ½", 
                k=3, 
                filters={"type": "definition"}
            )
            print(f"   å…ƒæ•°æ®è¿‡æ»¤: æ‰¾åˆ° {len(filtered_results)} ä¸ªå®šä¹‰ç±»æ–‡æ¡£")
            
            for doc in filtered_results:
                print(f"     æ¥æº: {doc.metadata.get('source')}, ç±»å‹: {doc.metadata.get('type')}")
            
    except Exception as e:
        print(f"   âš ï¸ å…ƒæ•°æ®è¿‡æ»¤æµ‹è¯•å¤±è´¥: {str(e)}")
    
    # æµ‹è¯•4: å¸¦é˜ˆå€¼æ£€ç´¢
    print("\nğŸ“ˆ æµ‹è¯•å¸¦é˜ˆå€¼æ£€ç´¢...")
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            store_manager = VectorStoreManager(persist_directory=temp_dir)
            store_manager.initialize_store(test_documents)
            
            retriever = Retriever(store_manager.vector_store)
            
            # å¸¦é˜ˆå€¼æœç´¢
            threshold_results = retriever.search_with_relevance_threshold(
                "ç¥ç»ç½‘ç»œ", 
                k=3, 
                score_threshold=0.1
            )
            print(f"   å¸¦é˜ˆå€¼æ£€ç´¢: æ‰¾åˆ° {len(threshold_results)} ä¸ªé«˜ç›¸å…³æ–‡æ¡£")
            
    except Exception as e:
        print(f"   âš ï¸ å¸¦é˜ˆå€¼æ£€ç´¢æµ‹è¯•å¤±è´¥: {str(e)}")
    
    # æµ‹è¯•5: é…ç½®æ›´æ–°
    print("\nâš™ï¸ æµ‹è¯•é…ç½®æ›´æ–°...")
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            store_manager = VectorStoreManager(persist_directory=temp_dir)
            store_manager.initialize_store(test_documents)
            
            retriever = Retriever(store_manager.vector_store)
            
            # æ›´æ–°é…ç½®
            retriever.update_search_config(k=2, filters={"topic": "nlp"})
            
            updated_info = retriever.get_retriever_info()
            print(f"   æ›´æ–°åé…ç½®: {updated_info}")
            
    except Exception as e:
        print(f"   âš ï¸ é…ç½®æ›´æ–°æµ‹è¯•å¤±è´¥: {str(e)}")
    
    print("\nğŸ¯ æ£€ç´¢å™¨æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_retriever()